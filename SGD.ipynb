{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place = pd.read_csv('../Data/whyout_data/place.csv') # shape(4697,10), place idx에서 23개가 비어있음\n",
    "# product = pd.read_csv('../Data/whyout_data/product.csv') # shape(5834,11), product idx에서 538개가 비어있음\n",
    "# video = pd.read_csv('../Data/whyout_data/video.csv') # shape(3250, 9), video idx에서 315개가 비어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_null_del_user_place = pd.read_csv('../Data/whyout_data/index_null_del_user_place.csv', index_col=0).astype(dtype='float16')\n",
    "index_null_del_user_product = pd.read_csv('../Data/whyout_data/index_null_del_user_product.csv', index_col=0).astype(dtype='float16')\n",
    "index_null_del_user_video = pd.read_csv('../Data/whyout_data/index_null_del_user_video.csv', index_col=0).astype(dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.7626\n",
      "Iteration: 20 ; cost = 0.7366\n",
      "Iteration: 30 ; cost = 0.7170\n",
      "Iteration: 40 ; cost = 0.6978\n",
      "Iteration: 50 ; cost = 0.6776\n",
      "Iteration: 60 ; cost = 0.6560\n",
      "Iteration: 70 ; cost = 0.6328\n",
      "Iteration: 80 ; cost = 0.6083\n",
      "Iteration: 90 ; cost = 0.5829\n",
      "Iteration: 100 ; cost = 0.5569\n",
      "Iteration: 110 ; cost = 0.5310\n",
      "Iteration: 120 ; cost = 0.5055\n",
      "Iteration: 130 ; cost = 0.4808\n",
      "Iteration: 140 ; cost = 0.4571\n",
      "Iteration: 150 ; cost = 0.4346\n",
      "Iteration: 160 ; cost = 0.4136\n",
      "Iteration: 170 ; cost = 0.3939\n",
      "Iteration: 180 ; cost = 0.3758\n",
      "Iteration: 190 ; cost = 0.3592\n",
      "Iteration: 200 ; cost = 0.3441\n",
      "Iteration: 210 ; cost = 0.3304\n",
      "Iteration: 220 ; cost = 0.3182\n",
      "Iteration: 230 ; cost = 0.3073\n",
      "Iteration: 240 ; cost = 0.2976\n",
      "Iteration: 250 ; cost = 0.2890\n",
      "Iteration: 260 ; cost = 0.2814\n",
      "Iteration: 270 ; cost = 0.2746\n",
      "Iteration: 280 ; cost = 0.2686\n",
      "Iteration: 290 ; cost = 0.2633\n",
      "Iteration: 300 ; cost = 0.2585\n",
      "Iteration: 310 ; cost = 0.2541\n",
      "Iteration: 320 ; cost = 0.2502\n",
      "Iteration: 330 ; cost = 0.2466\n",
      "Iteration: 340 ; cost = 0.2434\n",
      "Iteration: 350 ; cost = 0.2404\n",
      "Iteration: 360 ; cost = 0.2376\n",
      "Iteration: 370 ; cost = 0.2350\n",
      "Iteration: 380 ; cost = 0.2327\n",
      "Iteration: 390 ; cost = 0.2304\n",
      "Iteration: 400 ; cost = 0.2284\n",
      "Iteration: 410 ; cost = 0.2264\n",
      "Iteration: 420 ; cost = 0.2246\n",
      "Iteration: 430 ; cost = 0.2229\n",
      "Iteration: 440 ; cost = 0.2212\n",
      "Iteration: 450 ; cost = 0.2197\n",
      "Iteration: 460 ; cost = 0.2182\n",
      "Iteration: 470 ; cost = 0.2168\n",
      "Iteration: 480 ; cost = 0.2155\n",
      "Iteration: 490 ; cost = 0.2142\n",
      "Iteration: 500 ; cost = 0.2129\n",
      "Iteration: 510 ; cost = 0.2118\n",
      "Iteration: 520 ; cost = 0.2107\n",
      "Iteration: 530 ; cost = 0.2096\n",
      "Iteration: 540 ; cost = 0.2085\n",
      "Iteration: 550 ; cost = 0.2075\n",
      "Iteration: 560 ; cost = 0.2066\n",
      "Iteration: 570 ; cost = 0.2056\n",
      "Iteration: 580 ; cost = 0.2047\n",
      "Iteration: 590 ; cost = 0.2039\n",
      "Iteration: 600 ; cost = 0.2030\n",
      "Iteration: 610 ; cost = 0.2022\n",
      "Iteration: 620 ; cost = 0.2014\n",
      "Iteration: 630 ; cost = 0.2007\n",
      "Iteration: 640 ; cost = 0.1999\n",
      "Iteration: 650 ; cost = 0.1992\n",
      "Iteration: 660 ; cost = 0.1985\n",
      "Iteration: 670 ; cost = 0.1979\n",
      "Iteration: 680 ; cost = 0.1972\n",
      "Iteration: 690 ; cost = 0.1966\n",
      "Iteration: 700 ; cost = 0.1959\n",
      "Iteration: 710 ; cost = 0.1953\n",
      "Iteration: 720 ; cost = 0.1948\n",
      "Iteration: 730 ; cost = 0.1942\n",
      "Iteration: 740 ; cost = 0.1936\n",
      "Iteration: 750 ; cost = 0.1931\n",
      "Iteration: 760 ; cost = 0.1926\n",
      "Iteration: 770 ; cost = 0.1921\n",
      "Iteration: 780 ; cost = 0.1916\n",
      "Iteration: 790 ; cost = 0.1911\n",
      "Iteration: 800 ; cost = 0.1906\n",
      "Iteration: 810 ; cost = 0.1901\n",
      "Iteration: 820 ; cost = 0.1897\n",
      "Iteration: 830 ; cost = 0.1892\n",
      "Iteration: 840 ; cost = 0.1888\n",
      "Iteration: 850 ; cost = 0.1884\n",
      "Iteration: 860 ; cost = 0.1880\n",
      "Iteration: 870 ; cost = 0.1876\n",
      "Iteration: 880 ; cost = 0.1872\n",
      "Iteration: 890 ; cost = 0.1868\n",
      "Iteration: 900 ; cost = 0.1864\n",
      "Iteration: 910 ; cost = 0.1861\n",
      "Iteration: 920 ; cost = 0.1857\n",
      "Iteration: 930 ; cost = 0.1854\n",
      "Iteration: 940 ; cost = 0.1850\n",
      "Iteration: 950 ; cost = 0.1847\n",
      "Iteration: 960 ; cost = 0.1843\n",
      "Iteration: 970 ; cost = 0.1840\n",
      "Iteration: 980 ; cost = 0.1837\n",
      "Iteration: 990 ; cost = 0.1834\n",
      "Iteration: 1000 ; cost = 0.1831\n",
      "Iteration: 10 ; cost = 0.2156\n",
      "Iteration: 20 ; cost = 0.0954\n",
      "Iteration: 30 ; cost = 0.0520\n",
      "Iteration: 40 ; cost = 0.0328\n",
      "Iteration: 50 ; cost = 0.0250\n",
      "Iteration: 60 ; cost = 0.0221\n",
      "Iteration: 70 ; cost = 0.0211\n",
      "Iteration: 80 ; cost = 0.0207\n",
      "Iteration: 90 ; cost = 0.0205\n",
      "Iteration: 100 ; cost = 0.0205\n",
      "Iteration: 110 ; cost = 0.0205\n",
      "Iteration: 120 ; cost = 0.0210\n",
      "Iteration: 130 ; cost = 0.0280\n",
      "Iteration: 140 ; cost = 0.0956\n",
      "Iteration: 150 ; cost = 0.2630\n",
      "Iteration: 160 ; cost = 0.0848\n",
      "Iteration: 170 ; cost = 0.0243\n",
      "Iteration: 180 ; cost = 0.0207\n",
      "Iteration: 190 ; cost = 0.0206\n",
      "Iteration: 200 ; cost = 0.0207\n",
      "Iteration: 210 ; cost = 0.0212\n",
      "Iteration: 220 ; cost = 0.0238\n",
      "Iteration: 230 ; cost = 0.0362\n",
      "Iteration: 240 ; cost = 0.0789\n",
      "Iteration: 250 ; cost = 0.1611\n",
      "Iteration: 260 ; cost = 0.1340\n",
      "Iteration: 270 ; cost = 0.0545\n",
      "Iteration: 280 ; cost = 0.0557\n",
      "Iteration: 290 ; cost = 0.1740\n",
      "Iteration: 300 ; cost = 0.1420\n",
      "Iteration: 310 ; cost = 0.0449\n",
      "Iteration: 320 ; cost = 0.0339\n",
      "Iteration: 330 ; cost = 0.0440\n",
      "Iteration: 340 ; cost = 0.0654\n",
      "Iteration: 350 ; cost = 0.0997\n",
      "Iteration: 360 ; cost = 0.1400\n",
      "Iteration: 370 ; cost = 0.1601\n",
      "Iteration: 380 ; cost = 0.1457\n",
      "Iteration: 390 ; cost = 0.1169\n",
      "Iteration: 400 ; cost = 0.0946\n",
      "Iteration: 410 ; cost = 0.0933\n",
      "Iteration: 420 ; cost = 0.1252\n",
      "Iteration: 430 ; cost = 0.2317\n",
      "Iteration: 440 ; cost = 0.1620\n",
      "Iteration: 450 ; cost = 0.0590\n",
      "Iteration: 460 ; cost = 0.0393\n",
      "Iteration: 470 ; cost = 0.0321\n",
      "Iteration: 480 ; cost = 0.0289\n",
      "Iteration: 490 ; cost = 0.0275\n",
      "Iteration: 500 ; cost = 0.0270\n",
      "Iteration: 510 ; cost = 0.0273\n",
      "Iteration: 520 ; cost = 0.0284\n",
      "Iteration: 530 ; cost = 0.0309\n",
      "Iteration: 540 ; cost = 0.0364\n",
      "Iteration: 550 ; cost = 0.0478\n",
      "Iteration: 560 ; cost = 0.0692\n",
      "Iteration: 570 ; cost = 0.0982\n",
      "Iteration: 580 ; cost = 0.1110\n",
      "Iteration: 590 ; cost = 0.1295\n",
      "Iteration: 600 ; cost = 0.2824\n",
      "Iteration: 610 ; cost = 0.0837\n",
      "Iteration: 620 ; cost = 0.0830\n",
      "Iteration: 630 ; cost = 0.0979\n",
      "Iteration: 640 ; cost = 0.1100\n",
      "Iteration: 650 ; cost = 0.1139\n",
      "Iteration: 660 ; cost = 0.1089\n",
      "Iteration: 670 ; cost = 0.0989\n",
      "Iteration: 680 ; cost = 0.0894\n",
      "Iteration: 690 ; cost = 0.0851\n",
      "Iteration: 700 ; cost = 0.0884\n",
      "Iteration: 710 ; cost = 0.0945\n",
      "Iteration: 720 ; cost = 0.0919\n",
      "Iteration: 730 ; cost = 0.0790\n",
      "Iteration: 740 ; cost = 0.0857\n",
      "Iteration: 750 ; cost = 0.2737\n",
      "Iteration: 760 ; cost = 0.0795\n",
      "Iteration: 770 ; cost = 0.0438\n",
      "Iteration: 780 ; cost = 0.0426\n",
      "Iteration: 790 ; cost = 0.0435\n",
      "Iteration: 800 ; cost = 0.0463\n",
      "Iteration: 810 ; cost = 0.0517\n",
      "Iteration: 820 ; cost = 0.0604\n",
      "Iteration: 830 ; cost = 0.0725\n",
      "Iteration: 840 ; cost = 0.0853\n",
      "Iteration: 850 ; cost = 0.0923\n",
      "Iteration: 860 ; cost = 0.0910\n",
      "Iteration: 870 ; cost = 0.0875\n",
      "Iteration: 880 ; cost = 0.0884\n",
      "Iteration: 890 ; cost = 0.0984\n",
      "Iteration: 900 ; cost = 0.1750\n",
      "Iteration: 910 ; cost = 0.2123\n",
      "Iteration: 920 ; cost = 0.1079\n",
      "Iteration: 930 ; cost = 0.1046\n",
      "Iteration: 940 ; cost = 0.1012\n",
      "Iteration: 950 ; cost = 0.0967\n",
      "Iteration: 960 ; cost = 0.0931\n",
      "Iteration: 970 ; cost = 0.0908\n",
      "Iteration: 980 ; cost = 0.0873\n",
      "Iteration: 990 ; cost = 0.0808\n",
      "Iteration: 1000 ; cost = 0.0725\n",
      "Iteration: 10 ; cost = 0.4162\n",
      "Iteration: 20 ; cost = 0.3895\n",
      "Iteration: 30 ; cost = 0.3795\n",
      "Iteration: 40 ; cost = 0.3722\n",
      "Iteration: 50 ; cost = 0.3654\n",
      "Iteration: 60 ; cost = 0.3587\n",
      "Iteration: 70 ; cost = 0.3518\n",
      "Iteration: 80 ; cost = 0.3447\n",
      "Iteration: 90 ; cost = 0.3375\n",
      "Iteration: 100 ; cost = 0.3302\n",
      "Iteration: 110 ; cost = 0.3226\n",
      "Iteration: 120 ; cost = 0.3149\n",
      "Iteration: 130 ; cost = 0.3070\n",
      "Iteration: 140 ; cost = 0.2989\n",
      "Iteration: 150 ; cost = 0.2908\n",
      "Iteration: 160 ; cost = 0.2825\n",
      "Iteration: 170 ; cost = 0.2742\n",
      "Iteration: 180 ; cost = 0.2658\n",
      "Iteration: 190 ; cost = 0.2574\n",
      "Iteration: 200 ; cost = 0.2490\n",
      "Iteration: 210 ; cost = 0.2407\n",
      "Iteration: 220 ; cost = 0.2325\n",
      "Iteration: 230 ; cost = 0.2245\n",
      "Iteration: 240 ; cost = 0.2168\n",
      "Iteration: 250 ; cost = 0.2096\n",
      "Iteration: 260 ; cost = 0.2027\n",
      "Iteration: 270 ; cost = 0.1962\n",
      "Iteration: 280 ; cost = 0.1901\n",
      "Iteration: 290 ; cost = 0.1843\n",
      "Iteration: 300 ; cost = 0.1788\n",
      "Iteration: 310 ; cost = 0.1737\n",
      "Iteration: 320 ; cost = 0.1689\n",
      "Iteration: 330 ; cost = 0.1644\n",
      "Iteration: 340 ; cost = 0.1602\n",
      "Iteration: 350 ; cost = 0.1563\n",
      "Iteration: 360 ; cost = 0.1527\n",
      "Iteration: 370 ; cost = 0.1494\n",
      "Iteration: 380 ; cost = 0.1464\n",
      "Iteration: 390 ; cost = 0.1436\n",
      "Iteration: 400 ; cost = 0.1410\n",
      "Iteration: 410 ; cost = 0.1387\n",
      "Iteration: 420 ; cost = 0.1365\n",
      "Iteration: 430 ; cost = 0.1344\n",
      "Iteration: 440 ; cost = 0.1325\n",
      "Iteration: 450 ; cost = 0.1308\n",
      "Iteration: 460 ; cost = 0.1291\n",
      "Iteration: 470 ; cost = 0.1275\n",
      "Iteration: 480 ; cost = 0.1260\n",
      "Iteration: 490 ; cost = 0.1246\n",
      "Iteration: 500 ; cost = 0.1233\n",
      "Iteration: 510 ; cost = 0.1219\n",
      "Iteration: 520 ; cost = 0.1206\n",
      "Iteration: 530 ; cost = 0.1194\n",
      "Iteration: 540 ; cost = 0.1181\n",
      "Iteration: 550 ; cost = 0.1169\n",
      "Iteration: 560 ; cost = 0.1157\n",
      "Iteration: 570 ; cost = 0.1144\n",
      "Iteration: 580 ; cost = 0.1132\n",
      "Iteration: 590 ; cost = 0.1119\n",
      "Iteration: 600 ; cost = 0.1106\n",
      "Iteration: 610 ; cost = 0.1093\n",
      "Iteration: 620 ; cost = 0.1081\n",
      "Iteration: 630 ; cost = 0.1068\n",
      "Iteration: 640 ; cost = 0.1055\n",
      "Iteration: 650 ; cost = 0.1042\n",
      "Iteration: 660 ; cost = 0.1029\n",
      "Iteration: 670 ; cost = 0.1016\n",
      "Iteration: 680 ; cost = 0.1004\n",
      "Iteration: 690 ; cost = 0.0992\n",
      "Iteration: 700 ; cost = 0.0980\n",
      "Iteration: 710 ; cost = 0.0968\n",
      "Iteration: 720 ; cost = 0.0957\n",
      "Iteration: 730 ; cost = 0.0946\n",
      "Iteration: 740 ; cost = 0.0936\n",
      "Iteration: 750 ; cost = 0.0926\n",
      "Iteration: 760 ; cost = 0.0916\n",
      "Iteration: 770 ; cost = 0.0907\n",
      "Iteration: 780 ; cost = 0.0898\n",
      "Iteration: 790 ; cost = 0.0890\n",
      "Iteration: 800 ; cost = 0.0881\n",
      "Iteration: 810 ; cost = 0.0874\n",
      "Iteration: 820 ; cost = 0.0866\n",
      "Iteration: 830 ; cost = 0.0859\n",
      "Iteration: 840 ; cost = 0.0852\n",
      "Iteration: 850 ; cost = 0.0846\n",
      "Iteration: 860 ; cost = 0.0840\n",
      "Iteration: 870 ; cost = 0.0834\n",
      "Iteration: 880 ; cost = 0.0828\n",
      "Iteration: 890 ; cost = 0.0823\n",
      "Iteration: 900 ; cost = 0.0817\n",
      "Iteration: 910 ; cost = 0.0812\n",
      "Iteration: 920 ; cost = 0.0807\n",
      "Iteration: 930 ; cost = 0.0803\n",
      "Iteration: 940 ; cost = 0.0798\n",
      "Iteration: 950 ; cost = 0.0794\n",
      "Iteration: 960 ; cost = 0.0790\n",
      "Iteration: 970 ; cost = 0.0786\n",
      "Iteration: 980 ; cost = 0.0782\n",
      "Iteration: 990 ; cost = 0.0778\n",
      "Iteration: 1000 ; cost = 0.0775\n"
     ]
    }
   ],
   "source": [
    "# class MatrixFactorization():\n",
    "#     def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "#         \"\"\"\n",
    "#         :param R: rating matrix\n",
    "#         :param k: latent parameter\n",
    "#         :param learning_rate: alpha on weight update\n",
    "#         :param reg_param: beta on weight update\n",
    "#         :param epochs: training epochs\n",
    "#         :param verbose: print status\n",
    "#         \"\"\"\n",
    "#         self._R = R\n",
    "#         self._num_users, self._num_items = R.shape\n",
    "#         self._k = k\n",
    "#         self._learning_rate = learning_rate\n",
    "#         self._reg_param = reg_param\n",
    "#         self._epochs = epochs\n",
    "#         self._verbose = verbose\n",
    "\n",
    "\n",
    "#     def fit(self):\n",
    "#         \"\"\"\n",
    "#         training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "#         참고: self._b에 대한 설명\n",
    "#         - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "#         - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "#         :return: training_process\n",
    "#         \"\"\"\n",
    "#         # init latent features\n",
    "#         self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "#         self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "#         # init biases\n",
    "#         self._b_P = np.zeros(self._num_users)\n",
    "#         self._b_Q = np.zeros(self._num_items)\n",
    "#         self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "#         # train while epochs\n",
    "#         self._training_process = []\n",
    "#         for epoch in range(self._epochs):\n",
    "#             # rating이 존재하는 index를 기준으로 training\n",
    "#             xi, yi = self._R.nonzero()\n",
    "#             for i, j in zip(xi, yi):\n",
    "#                 self.gradient_descent(i, j, self._R[i, j])\n",
    "#             cost = self.cost()\n",
    "#             self._training_process.append((epoch, cost))\n",
    "\n",
    "#             # print status\n",
    "#             if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "#                 print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "#     def cost(self):\n",
    "#         \"\"\"\n",
    "#         compute root mean square error\n",
    "#         :return: rmse cost\n",
    "#         \"\"\"\n",
    "#         # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "#         xi, yi = self._R.nonzero()\n",
    "#         # predicted = self.get_complete_matrix()\n",
    "#         cost = 0\n",
    "#         for x, y in zip(xi, yi):\n",
    "#             cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "#         return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "#     def gradient(self, error, i, j):\n",
    "#         \"\"\"\n",
    "#         gradient of latent feature for GD\n",
    "#         :param error: rating - prediction error\n",
    "#         :param i: user index\n",
    "#         :param j: item index\n",
    "#         :return: gradient of latent feature tuple\n",
    "#         \"\"\"\n",
    "#         dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "#         dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "#         return dp, dq\n",
    "\n",
    "\n",
    "#     def gradient_descent(self, i, j, rating):\n",
    "#         \"\"\"\n",
    "#         graident descent function\n",
    "#         :param i: user index of matrix\n",
    "#         :param j: item index of matrix\n",
    "#         :param rating: rating of (i,j)\n",
    "#         \"\"\"\n",
    "#         # get error\n",
    "#         prediction = self.get_prediction(i, j)\n",
    "#         error = rating - prediction\n",
    "\n",
    "#         # update biases\n",
    "#         self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "#         self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "#         # update latent feature\n",
    "#         dp, dq = self.gradient(error, i, j)\n",
    "#         self._P[i, :] += self._learning_rate * dp\n",
    "#         self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "#     def get_prediction(self, i, j):\n",
    "#         \"\"\"\n",
    "#         get predicted rating: user_i, item_j\n",
    "#         :return: prediction of r_ij\n",
    "#         \"\"\"\n",
    "#         return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "#     def get_complete_matrix(self):\n",
    "#         \"\"\"\n",
    "#         computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "#         - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "#         - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "#         - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "#         - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "#         :return: complete matrix R^\n",
    "#         \"\"\"\n",
    "#         return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)\n",
    "    \n",
    "#     def print_results(self):\n",
    "#         \"\"\"\n",
    "#         print fit results\n",
    "#         \"\"\"\n",
    "#         print(\"User Latent P:\")\n",
    "#         print(self._P)\n",
    "#         print(\"Item Latent Q:\")\n",
    "#         print(self._Q.T)\n",
    "#         print(\"P x Q:\")\n",
    "#         print(self._P.dot(self._Q.T))\n",
    "#         print(\"bias:\")\n",
    "#         print(self._b)\n",
    "#         print(\"User Latent bias:\")\n",
    "#         print(self._b_P)\n",
    "#         print(\"Item Latent bias:\")\n",
    "#         print(self._b_Q)\n",
    "#         print(\"Final R matrix:\")\n",
    "#         print(self.get_complete_matrix())\n",
    "#         print(\"Final RMSE:\")\n",
    "#         print(self._training_process[self._epochs-1][1])\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # rating matrix - User X Item : (25827 X 4697)\n",
    "#     # P, Q is (25827 X k), (k X 4697) matrix\n",
    "#     R = np.array(index_null_del_user_place)\n",
    "#     factorizer = MatrixFactorization(R, k=50, learning_rate=0.01, reg_param=0.01, epochs=1000, verbose=True)\n",
    "#     factorizer.fit()\n",
    "#     #factorizer.print_results()\n",
    "#     complete_matrix = factorizer.get_complete_matrix()\n",
    "\n",
    "#     R1 = np.array(index_null_del_user_product)\n",
    "#     factorizer = MatrixFactorization(R1, k=50, learning_rate=0.01, reg_param=0.01, epochs=1000, verbose=True)\n",
    "#     factorizer.fit()\n",
    "#     #factorizer.print_results()\n",
    "#     complete_matrix1 = factorizer.get_complete_matrix()\n",
    "\n",
    "\n",
    "#     R2 = np.array(index_null_del_user_video)\n",
    "#     factorizer = MatrixFactorization(R2, k=50, learning_rate=0.01, reg_param=0.01, epochs=1000, verbose=True)\n",
    "#     factorizer.fit()\n",
    "#     #factorizer.print_results()\n",
    "#     complete_matrix2 = factorizer.get_complete_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(user_id, recommendation_num, item, R):\n",
    "    \"\"\"\n",
    "    사용자에게 아이템을 추천하는 함수\n",
    "    \n",
    "    :param user_id: 사용자 인덱스\n",
    "    :param recommendation_num: 추천할 아이템 개수\n",
    "    :param item: 예측된 평점 행렬\n",
    "    :param R: 실제 사용자 평점 행렬\n",
    "    :return: 추천된 아이템 인덱스 리스트\n",
    "    \"\"\"\n",
    "    user_ratings = R[user_id, :]  # 해당 사용자의 평가 데이터\n",
    "    predictions = item[user_id, :]  # 모델의 예측 점수\n",
    "\n",
    "    # 사용자가 이미 평가한 아이템은 -inf로 설정하여 추천 대상에서 제외\n",
    "    recommended_items = np.where(user_ratings != 0, -np.inf, predictions)\n",
    "\n",
    "    # 예측 점수가 가장 높은 상위 n개 아이템 추천\n",
    "    top_recommended_item_indices = np.argsort(recommended_items)[-recommendation_num:][::-1]\n",
    "\n",
    "    return top_recommended_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_place_df = pd.read_csv('../Data/whyout_data/sgd_result/complete_matrix_place.csv', index_col=0)\n",
    "sgd_product_df = pd.read_csv('../Data/whyout_data/sgd_result/complete_matrix_product.csv', index_col=0)\n",
    "sgd_video_df = pd.read_csv('../Data/whyout_data/sgd_result/complete_matrix_video.csv', index_col=0)\n",
    "place_item = np.array(sgd_place_df)\n",
    "product_item = np.array(sgd_product_df)\n",
    "video_item = np.array(sgd_video_df)\n",
    "R_place = np.array(index_null_del_user_place)\n",
    "R_product = np.array(index_null_del_user_product)\n",
    "R_video = np.array(index_null_del_user_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 2에게 추천해줄 10개 아이템 id : [1025 4498 1565 1439  586 4363  810 1477 1284 2581]\n"
     ]
    }
   ],
   "source": [
    "# 사용자 선택\n",
    "user_id = 2\n",
    "recommendation_num = 10\n",
    "item = [place_item, product_item, video_item]\n",
    "R = [R_place, R_product, R_video]\n",
    "\n",
    "top_recommended_item_indices = recommend_items(user_id, recommendation_num, item[0], R[0])\n",
    "\n",
    "print(f\"user {user_id}에게 추천해줄 {recommendation_num}개 아이템 id : {top_recommended_item_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(complete_matrix2).astype(dtype='float16')\n",
    "# df.to_csv('complete_matrix_video.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
