{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:26:58.300674Z",
     "start_time": "2024-05-20T07:26:56.777743Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_csv('../Data/whyout_data/user.csv') # (31177,3)\n",
    "drop_user_place_idx = pd.read_csv('../Data/whyout_data/drop_user_place_idx.csv') # (22420,4)\n",
    "drop_user_product_idx = pd.read_csv('../Data/whyout_data/drop_user_product_idx.csv') # (2294,4)\n",
    "drop_user_video_idx = pd.read_csv('../Data/whyout_data/drop_user_video_idx.csv') # (11067, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = pd.read_csv('../Data/whyout_data/place.csv') # shape(4697,10)\n",
    "product = pd.read_csv('../Data/whyout_data/product.csv') # shape(5821,11)\n",
    "video = pd.read_csv('../Data/whyout_data/video.csv') # shape(3250, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_place = pd.read_csv('../Data/whyout_data/col_user_place.csv') # (31177,4697)\n",
    "user_product = pd.read_csv('../Data/whyout_data/col_user_product.csv') # (31177,5821)\n",
    "user_video = pd.read_csv('../Data/whyout_data/col_user_video.csv') # (31177, 3250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_user_place = pd.read_csv('../Data/whyout_data/drop_user_place.csv') # (22420,4697) \n",
    "drop_user_product = pd.read_csv('../Data/whyout_data/drop_user_product.csv') # (2994,5821)\n",
    "drop_user_video = pd.read_csv('../Data/whyout_data/drop_user_video.csv') # (11067, 3250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "        self.cost_list = []\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "        # init latent features\n",
    "        self._U = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._V = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_U = np.zeros(self._num_users)\n",
    "        self._b_V = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            xi, yi = self._R.nonzero()\n",
    "            for i, j in zip(xi, yi):\n",
    "                self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                self.cost_list.append(cost)\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "        return self.cost_list\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        xi, yi = self._R.nonzero()\n",
    "        # predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        #print(len(xi), len(yi))\n",
    "        count = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            count += 1\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "            # if self._R[x,y]== 6:\n",
    "            #     print(cost, self._R[x,y], self.get_prediction(x,y))\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "        du = (error * self._V[j, :]) - (self._reg_param * self._U[i, :]) # user에 대해 gradient -> item에 대해 미분\n",
    "        dv = (error * self._U[i, :]) - (self._reg_param * self._V[j, :])\n",
    "        return du, dv\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_U[i] += self._learning_rate * (error - self._reg_param * self._b_U[i])\n",
    "        self._b_V[j] += self._learning_rate * (error - self._reg_param * self._b_V[j])\n",
    "\n",
    "        # update latent feature\n",
    "        du, dv = self.gradient(error, i, j)\n",
    "        self._U[i, :] += self._learning_rate * du\n",
    "        self._V[j, :] += self._learning_rate * dv\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_U[i] + self._b_V[j] + self._U[i, :].dot(self._V[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix UXV + U.bias + V.bias + global bias\n",
    "\n",
    "        - UXV 행렬에 b_U[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_V[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_U[:, np.newaxis] + self._b_V[np.newaxis:, ] + self._U.dot(self._V.T)\n",
    "    \n",
    "    def print_results(self):\n",
    "        print(\"User Latent U:\")\n",
    "        print(self._U)\n",
    "        print(\"Item Latent V:\")\n",
    "        print(self._V.T)\n",
    "        print(\"U x V:\")\n",
    "        print(self._U.dot(self._V.T))\n",
    "        print(\"bias:\")\n",
    "        print(self._b)\n",
    "        print(\"User Latent bias:\")\n",
    "        print(self._b_U)\n",
    "        print(\"Item Latent bias:\")\n",
    "        print(self._b_V)\n",
    "        print(\"Final R matrix:\")\n",
    "        print(self.get_complete_matrix())\n",
    "        print(\"Final RMSE:\")\n",
    "        print(self._training_process[self._epochs-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : (사용자 수 X 아이템 수)\n",
    "    # U, V is (사용자 수 X k), (k X 아이템 수) matrix\n",
    "    R = np.array(drop_user_place)\n",
    "    factorizer = SGD(R, k=30, learning_rate=0.01, reg_param=0.01, epochs=2000, verbose=True)\n",
    "    cost_list = factorizer.fit()\n",
    "    complete_matrix = factorizer.get_complete_matrix()\n",
    "\n",
    "    R1 = np.array(drop_user_product)\n",
    "    factorizer = SGD(R1, k=30, learning_rate=0.01, reg_param=0.01, epochs=2000, verbose=True)\n",
    "    cost_list1 = factorizer.fit()\n",
    "    complete_matrix1 = factorizer.get_complete_matrix()\n",
    "\n",
    "    R2 = np.array(drop_user_video)\n",
    "    factorizer = SGD(R2, k=30, learning_rate=0.01, reg_param=0.01, epochs=2000, verbose=True)\n",
    "    cost_list2 = factorizer.fit()\n",
    "    complete_matrix2 = factorizer.get_complete_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(complete_matrix).astype(dtype='float16')\n",
    "df.to_csv('../Data/whyout_data/sgd_result/del_data/user_place_k30epochs2000.csv', index=False)\n",
    "\n",
    "df1 = pd.DataFrame(complete_matrix1).astype(dtype='float16')\n",
    "df1.to_csv('../Data/whyout_data/sgd_result/del_data/user_product_k30epochs2000.csv', index=False)\n",
    "\n",
    "df2 = pd.DataFrame(complete_matrix2).astype(dtype='float16')\n",
    "df2.to_csv('../Data/whyout_data/sgd_result/del_data/user_video_k30epochs2000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGD_cost_regularization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "        self.cost_list = []\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "        # init latent features\n",
    "        self._U = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._V = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        #self._b_U = np.zeros(self._num_users)\n",
    "        #self._b_V = np.zeros(self._num_items)\n",
    "        #self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            xi, yi = self._R.nonzero()\n",
    "            for i, j in zip(xi, yi):\n",
    "                self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                self.cost_list.append(cost)\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "        return self.cost_list\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error with regularization\n",
    "        :return: rmse cost with regularization\n",
    "        \"\"\"\n",
    "        xi, yi = self._R.nonzero()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        \n",
    "        # Add regularization terms\n",
    "        cost += self._reg_param * (\n",
    "            np.sum(np.square(self._U)) +\n",
    "            np.sum(np.square(self._V))\n",
    "        )\n",
    "        \n",
    "        return np.sqrt(cost / len(xi))\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "        du = (error * self._V[j, :]) - (self._reg_param * self._U[i, :])\n",
    "        dv = (error * self._U[i, :]) - (self._reg_param * self._V[j, :])\n",
    "        return du, dv\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        #self._b_U[i] += self._learning_rate * (error - self._reg_param * self._b_U[i])\n",
    "        #self._b_V[j] += self._learning_rate * (error - self._reg_param * self._b_V[j])\n",
    "\n",
    "        # update latent feature\n",
    "        du, dv = self.gradient(error, i, j)\n",
    "        self._U[i, :] += self._learning_rate * du\n",
    "        self._V[j, :] += self._learning_rate * dv\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._U[i, :].dot(self._V[j, :].T)\n",
    "    \n",
    "    def get_user_latent(self):\n",
    "        return self._U\n",
    "    \n",
    "    def get_item_latent(self):\n",
    "        return self._V\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix UXV + U.bias + V.bias + global bias\n",
    "\n",
    "        - UXV 행렬에 b_U[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_V[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._U.dot(self._V.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.8934\n",
      "Iteration: 20 ; cost = 0.7686\n",
      "Iteration: 30 ; cost = 0.7284\n",
      "Iteration: 40 ; cost = 0.7011\n",
      "Iteration: 50 ; cost = 0.6768\n",
      "Iteration: 60 ; cost = 0.6529\n",
      "Iteration: 70 ; cost = 0.6287\n",
      "Iteration: 80 ; cost = 0.6042\n",
      "Iteration: 90 ; cost = 0.5793\n",
      "Iteration: 100 ; cost = 0.5546\n",
      "Iteration: 110 ; cost = 0.5304\n",
      "Iteration: 120 ; cost = 0.5069\n",
      "Iteration: 130 ; cost = 0.4845\n",
      "Iteration: 140 ; cost = 0.4634\n",
      "Iteration: 150 ; cost = 0.4436\n",
      "Iteration: 160 ; cost = 0.4252\n",
      "Iteration: 170 ; cost = 0.4082\n",
      "Iteration: 180 ; cost = 0.3925\n",
      "Iteration: 190 ; cost = 0.3781\n",
      "Iteration: 200 ; cost = 0.3650\n",
      "Iteration: 210 ; cost = 0.3532\n",
      "Iteration: 220 ; cost = 0.3425\n",
      "Iteration: 230 ; cost = 0.3329\n",
      "Iteration: 240 ; cost = 0.3244\n",
      "Iteration: 250 ; cost = 0.3168\n",
      "Iteration: 260 ; cost = 0.3101\n",
      "Iteration: 270 ; cost = 0.3040\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # rating matrix - User X Item : (사용자 수 X 아이템 수)\n",
    "    # U, V is (사용자 수 X k), (k X 아이템 수) matrix\n",
    "    R3 = np.array(drop_user_place)\n",
    "    factorizer = SGD_cost_regularization(R3, k=50, learning_rate=0.01, reg_param=0.01, epochs=2000, verbose=True)\n",
    "    cost_list3 = factorizer.fit()\n",
    "    complete_matrix3 = factorizer.get_complete_matrix()\n",
    "    user_latent3 = factorizer.get_user_latent()\n",
    "    item_latent3 = factorizer.get_item_latent()\n",
    "\n",
    "    R4 = np.array(drop_user_product)\n",
    "    factorizer = SGD_cost_regularization(R4, k=50, learning_rate=0.01, reg_param=0.01, epochs=2000, verbose=True)\n",
    "    cost_list4 = factorizer.fit()\n",
    "    complete_matrix4 = factorizer.get_complete_matrix()\n",
    "    user_latent4 = factorizer.get_user_latent()\n",
    "    item_latent4 = factorizer.get_item_latent()\n",
    "\n",
    "    R5 = np.array(drop_user_video)\n",
    "    factorizer = SGD_cost_regularization(R5, k=50, learning_rate=0.01, reg_param=0.01, epochs=2000, verbose=True)\n",
    "    cost_list5 = factorizer.fit()\n",
    "    complete_matrix5 = factorizer.get_complete_matrix()\n",
    "    user_latent5 = factorizer.get_user_latent()\n",
    "    item_latent5 = factorizer.get_item_latent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(cost_list3)\n",
    "plt.savefig('drop_user_place_regularizationk50epochs2000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(cost_list3)\n",
    "plt.savefig('drop_user_product_regularizationk50epochs2000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(cost_list3)\n",
    "plt.savefig('drop_user_video_regularizationk50epochs2000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(complete_matrix3).astype(dtype='float16')\n",
    "df3.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_place_regularizationk50epochs2000.csv', index=False)\n",
    "cost_list3 = pd.DataFrame(cost_list3).astype(dtype='float16')\n",
    "cost_list3.to_csv('drop_user_place_regularizationk50epochs2000.csv', index=False)\n",
    "get_user_latent3 = pd.DataFrame(user_latent3).astype(dtype='float16')\n",
    "get_user_latent3.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_place_user_latent_regularizationk50epochs2000.csv', index=False)\n",
    "get_item_latent3 = pd.DataFrame(item_latent3).astype(dtype='float16')\n",
    "get_item_latent3.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_place_item_latent_regularizationk50epochs2000.csv', index=False)\n",
    "\n",
    "\n",
    "df4 = pd.DataFrame(complete_matrix4).astype(dtype='float16')\n",
    "df4.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_product_regularizationk50epochs2000.csv', index=False)\n",
    "cost_list4 = pd.DataFrame(cost_list4).astype(dtype='float16')\n",
    "cost_list4.to_csv('drop_user_product_regularizationk50epochs2000.csv', index=False)\n",
    "get_user_latent4 = pd.DataFrame(user_latent4).astype(dtype='float16')\n",
    "get_user_latent4.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_product_user_latent_regularizationk50epochs2000.csv', index=False)\n",
    "get_item_latent4 = pd.DataFrame(item_latent4).astype(dtype='float16')\n",
    "get_item_latent4.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_product_item_latent_regularizationk50epochs2000.csv', index=False)\n",
    "\n",
    "\n",
    "df5 = pd.DataFrame(complete_matrix5).astype(dtype='float16')\n",
    "df5.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_video_regularizationk50epochs2000.csv', index=False)\n",
    "cost_list5 = pd.DataFrame(cost_list5).astype(dtype='float16')\n",
    "cost_list5.to_csv('drop_user_video_regularizationk50epochs2000.csv', index=False)\n",
    "get_user_latent5 = pd.DataFrame(user_latent5).astype(dtype='float16')\n",
    "get_user_latent5.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_video_user_latent_regularizationk50epochs2000.csv', index=False)\n",
    "get_item_latent5 = pd.DataFrame(item_latent5).astype(dtype='float16')\n",
    "get_item_latent5.to_csv('../Data/whyout_data/sgd_result/del_data/drop_user_video_item_latent_regularizationk50epochs2000.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
