{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = pd.read_csv('../Data/whyout_data/place.csv') # shape(4697,10), place idx에서 23개가 비어있음\n",
    "product = pd.read_csv('../Data/whyout_data/product.csv') # shape(5834,11), product idx에서 538개가 비어있음\n",
    "video = pd.read_csv('../Data/whyout_data/video.csv') # shape(3250, 9), video idx에서 315개가 비어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_null_del_user_place = pd.read_csv('../Data/whyout_data/index_null_del_user_place.csv', index_col=0)\n",
    "index_null_del_user_product = pd.read_csv('../Data/whyout_data/index_null_del_user_product.csv', index_col=0)\n",
    "index_null_del_user_video = pd.read_csv('../Data/whyout_data/index_null_del_user_video.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter Setting\n",
    "r_lambda = 40\n",
    "nf = 20\n",
    "alpha = 40\n",
    "\n",
    "R = index_null_del_user_place #shape = (25827, 4697)\n",
    "nu, ni = R.shape[0], R.shape[1]\n",
    "\n",
    "X = np.random.rand(nu, nf) * 0.01 #shape = (25827, 20)\n",
    "Y = np.random.rand(ni, nf) * 0.01 #shape = (4697, 20)\n",
    "\n",
    "P = np.copy(R)\n",
    "P[P > 0] = 1\n",
    "C = 1 + alpha * R # alpha = 40\n",
    "C = C.to_numpy()\n",
    "\n",
    "def loss_function(C, P, xTy, X, Y, r_lambda):\n",
    "    predict_error = np.square(P - xTy)\n",
    "    confidence_error = np.sum(C * predict_error)\n",
    "    regularization = r_lambda * (np.sum(np.square(X)) + np.sum(np.square(Y)))\n",
    "    total_loss = confidence_error + regularization\n",
    "    return np.sum(predict_error), confidence_error, regularization, total_loss\n",
    "\n",
    "def optimize_user(X, Y, C, P, nu, nf, r_lambda):\n",
    "    # Y = number of Items, shape = (4697, 20)\n",
    "    yT = np.transpose(Y) # shape = (20, 4697)\n",
    "    for u in range(nu):\n",
    "        Cu = np.diag(C[u]) # shape = (25827, 25827)\n",
    "        yT_Cu_y = np.matmul(np.matmul(yT, Cu), Y) #{(20, 25827)*(25827, 25827)}*(25827, 20) = (20, 20)\n",
    "        lI = np.dot(r_lambda, np.identity(nf))\n",
    "        yT_Cu_pu = np.matmul(np.matmul(yT, Cu), P[u])\n",
    "        X[u] = np.linalg.solve(yT_Cu_y + lI, yT_Cu_pu)\n",
    "\n",
    "def optimize_item(X, Y, C, P, ni, nf, r_lambda):\n",
    "    # X = number of users, shape = (25827, 20)\n",
    "    xT = np.transpose(X) #shape = (20, 25827)\n",
    "    for i in range(ni):\n",
    "        Ci = np.diag(C[:, i]) #shape = (4697, 4697)\n",
    "        xT_Ci_x = np.matmul(np.matmul(xT, Ci), X) #{(20, 4697)*(4697, 4697)}*(4697, 20) = (20, 20)\n",
    "        lI = np.dot(r_lambda, np.identity(nf))\n",
    "        xT_Ci_pi = np.matmul(np.matmul(xT, Ci), P[:, i])\n",
    "        Y[i] = np.linalg.solve(xT_Ci_x + lI, xT_Ci_pi)\n",
    "\n",
    "# Run Learning\n",
    "predict_errors = []\n",
    "confidence_errors = []\n",
    "regularization_list = []\n",
    "total_losses = []\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    if i%2 == 0:   \n",
    "        optimize_user(X, Y, C, P, nu, nf, r_lambda)\n",
    "        optimize_item(X, Y, C, P, ni, nf, r_lambda)\n",
    "        print(i)\n",
    "    else:\n",
    "        optimize_item(X, Y, C, P, ni, nf, r_lambda)\n",
    "        optimize_user(X, Y, C, P, nu, nf, r_lambda)\n",
    "        \n",
    "    predict = np.matmul(X, np.transpose(Y))\n",
    "    predict_error, confidence_error, regularization, total_loss = loss_function(C, P, predict, X, Y, r_lambda)\n",
    "    \n",
    "    predict_errors.append(predict_error)\n",
    "    confidence_errors.append(confidence_error)\n",
    "    regularization_list.append(regularization)\n",
    "    total_losses.append(total_loss)\n",
    "\n",
    "plt.subplots_adjust(wspace=100.0, hspace=20.0)\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "predict_error_line = fig.add_subplot(2, 2, 1)\n",
    "confidence_error_line = fig.add_subplot(2, 2, 2)\n",
    "regularization_error_line = fig.add_subplot(2, 2, 3)\n",
    "total_loss_line = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "predict_error_line.set_title(\"Predict Error\") \n",
    "predict_error_line.plot(predict_errors)\n",
    "\n",
    "confidence_error_line.set_title(\"Confidence Error\")\n",
    "confidence_error_line.plot(confidence_errors)\n",
    "\n",
    "regularization_error_line.set_title(\"Regularization\")\n",
    "regularization_error_line.plot(regularization_list)\n",
    "\n",
    "total_loss_line.set_title(\"Total Loss\")\n",
    "total_loss_line.plot(total_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing movie IDs from movie_data: {8005, 7847, 1383, 5545, 6346, 1166, 6833, 7860, 7670, 7703, 8446}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>534</td>\n",
       "      <td>Shadowlands (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1348</td>\n",
       "      <td>Nosferatu (Nosferatu, eine Symphonie des Graue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1642</td>\n",
       "      <td>Indian Summer (a.k.a. Alive &amp; Kicking) (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>2991</td>\n",
       "      <td>Live and Let Die (1973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>4052</td>\n",
       "      <td>Antitrust (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>5027</td>\n",
       "      <td>Another 48 Hrs. (1990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>6424</td>\n",
       "      <td>Oscar (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>6516</td>\n",
       "      <td>Anastasia (1956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>7055</td>\n",
       "      <td>Swing Time (1936)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                              title\n",
       "478       534                                 Shadowlands (1993)\n",
       "1092     1348  Nosferatu (Nosferatu, eine Symphonie des Graue...\n",
       "1306     1642      Indian Summer (a.k.a. Alive & Kicking) (1996)\n",
       "2402     2991                            Live and Let Die (1973)\n",
       "3247     4052                                   Antitrust (2001)\n",
       "3897     5027                             Another 48 Hrs. (1990)\n",
       "4634     6424                                       Oscar (1991)\n",
       "4678     6516                                   Anastasia (1956)\n",
       "4959     7055                                  Swing Time (1936)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALS 알고리즘 종료 후\n",
    "# 1. 예측 행렬 생성 2. 추천 대상 선정 3. 추천\n",
    "def recommend_movies(predict_matrix, user_id, original_ratings, num_recommendations=5):\n",
    "    # 사용자의 평가 데이터를 가져옴\n",
    "    user_rating = original_ratings.iloc[user_id].values\n",
    "    unrated_movies = np.where(user_rating == 0)[0]\n",
    "    rated_movies = np.where(user_rating == 1)[0]\n",
    "    #print(len(rated_movies))\n",
    "    #print(len(unrated_movies))\n",
    "\n",
    "    # 평가하지 않은 영화에 대한 예측 점수 추출\n",
    "    recommendations = predict_matrix[user_id, unrated_movies]\n",
    "\n",
    "    # 가장 높은 예측 점수를 가진 영화 인덱스 추출\n",
    "    recommended_movie_indices = np.argsort(recommendations)[::-1][:num_recommendations]\n",
    "    top_movie_indices = np.argsort(predict[user_id])[-5:][::-1]\n",
    "    top_movie_scores = predict[user_id][top_movie_indices]\n",
    "    \n",
    "    #print(\"Top 5 predicted scores and their movie indices:\")\n",
    "    #print(list(zip(top_movie_indices, top_movie_scores)))\n",
    "\n",
    "    # 영화 ID 추출\n",
    "    recommended_movie_ids = unrated_movies[recommended_movie_indices]\n",
    "\n",
    "    # 영화 제목 매핑\n",
    "    recommended_movies = movie_data[movie_data['movieId'].isin(recommended_movie_ids)]\n",
    "    missing_ids = set(recommended_movie_ids) - set(recommended_movies['movieId'])\n",
    "    \n",
    "    if missing_ids:\n",
    "        print(f\"Missing movie IDs from movie_data: {missing_ids}\")\n",
    "\n",
    "    return recommended_movies[['movieId', 'title']]\n",
    "    # recommended_movies = movie_data.loc[movie_data['movieId'].isin(recommended_movie_ids)]\n",
    "    # print(recommend_movies)\n",
    "    # return recommended_movies[['movieId', 'title']]\n",
    "\n",
    "# 예측 행렬 생성\n",
    "predict = np.matmul(X, Y.T)\n",
    "\n",
    "# 사용자 ID 예시 (예: 첫 번째 사용자)\n",
    "user_id = 10\n",
    "recommended_movies = recommend_movies(predict, user_id, R, num_recommendations=20)\n",
    "recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천된 영화 수: 9\n",
      "추천된 영화 IDs: [534, 1348, 1642, 2991, 4052, 5027, 6424, 6516, 7055]\n",
      "사용자 10가(이) 평점 4 이상으로 평가한 영화 수: 28\n",
      "사용자가 높게 평가한 영화 IDs: [50, 152, 318, 345, 735, 1127, 1196, 1197, 1198, 1200, 1210, 1240, 1291, 1358, 1423, 1611, 1704, 1719, 1923, 2344, 2406, 2539, 2571, 2826, 2841, 2890, 2926, 3019]\n"
     ]
    }
   ],
   "source": [
    "def print_diagnostics(user_id, recommendations, actual_ratings):\n",
    "    print(f\"추천된 영화 수: {len(recommendations)}\")\n",
    "    if len(recommendations) > 0:\n",
    "        print(\"추천된 영화 IDs:\", recommendations['movieId'].tolist())\n",
    "    \n",
    "    actual_liked_movies = actual_ratings[(actual_ratings['userId'] == user_id) & (actual_ratings['rating'] >= 4.0)]\n",
    "    print(f\"사용자 {user_id}가(이) 평점 4 이상으로 평가한 영화 수: {len(actual_liked_movies)}\")\n",
    "    if len(actual_liked_movies) > 0:\n",
    "        print(\"사용자가 높게 평가한 영화 IDs:\", actual_liked_movies['movieId'].tolist())\n",
    "\n",
    "# 추천 결과 및 실제 사용자 평가 데이터 진단\n",
    "print_diagnostics(user_id, recommended_movies, rating_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
